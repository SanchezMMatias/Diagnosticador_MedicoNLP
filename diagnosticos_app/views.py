import os
import json
import torch
import librosa
import traceback
from transformers import AutoTokenizer, AutoModelForSequenceClassification

from django.shortcuts import render, get_object_or_404
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
from django.views.decorators.http import require_http_methods

from transformers import WhisperProcessor, WhisperForConditionalGeneration
from safetensors.torch import load_file

from audio_app.models import AudioMedico
from .models import Diagnostico

import soundfile as sf
import numpy as np
from pydub import AudioSegment
from pydub.utils import which
import tempfile
import wave
import struct
from datetime import datetime

# Configurar FFmpeg para pydub
def setup_ffmpeg():
    """Configura FFmpeg para pydub."""
    try:
        # Tu ruta personalizada de FFmpeg
        custom_ffmpeg_path = r"C:\Users\adm97\Downloads\ffmpeg-7.1.1-essentials_build\bin\ffmpeg.exe"
        
        # Verificar si existe tu ruta personalizada primero
        if os.path.exists(custom_ffmpeg_path):
            AudioSegment.converter = custom_ffmpeg_path
            print(f"‚úÖ FFmpeg configurado con tu ruta personalizada: {custom_ffmpeg_path}")
            return True
        
        # Intentar encontrar FFmpeg en el sistema como fallback
        ffmpeg_path = which("ffmpeg")
        if ffmpeg_path:
            AudioSegment.converter = ffmpeg_path
            print(f"‚úÖ FFmpeg encontrado en el sistema: {ffmpeg_path}")
            return True
        
        # Rutas comunes donde podr√≠a estar FFmpeg como √∫ltimo recurso
        possible_paths = [
            r"C:\ffmpeg\bin\ffmpeg.exe",
            r"C:\Program Files\ffmpeg\bin\ffmpeg.exe",
            r"C:\Program Files (x86)\ffmpeg\bin\ffmpeg.exe",
            "/usr/bin/ffmpeg",
            "/usr/local/bin/ffmpeg",
            "/opt/homebrew/bin/ffmpeg"  # macOS con Homebrew
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                AudioSegment.converter = path
                print(f"‚úÖ FFmpeg configurado en ruta com√∫n: {path}")
                return True
        
        print("‚ö†Ô∏è FFmpeg no encontrado en ninguna ruta")
        return False
    except Exception as e:
        print(f"‚ö†Ô∏è Error configurando FFmpeg: {e}")
        return False

# Llamar a la configuraci√≥n al inicio
setup_ffmpeg()

# Rutas a los modelos
WHISPER_MODEL_PATH = r"D:\archivos Universidad\IA\Lab03IA\audio_app\models\model.safetensors"
CLINICAL_MODEL_PATH = r"D:\archivos Universidad\IA\Lab03IA\audio_app\models\clinical_bert_diagnostic_model_group.pth"

# Variables globales para los modelos
whisper_processor = None
whisper_model = None
clinical_tokenizer = None
clinical_model = None

def load_custom_whisper_model():
    """Carga el modelo Whisper personalizado."""
    global whisper_processor, whisper_model
    if whisper_processor is not None and whisper_model is not None:
        return

    print("--- üöÄ Iniciando carga del modelo Whisper PERSONALIZADO ---")
    
    if not os.path.exists(WHISPER_MODEL_PATH):
        error_msg = f"ERROR CR√çTICO: No se encontr√≥ el modelo Whisper en {WHISPER_MODEL_PATH}"
        print(f"‚ùå {error_msg}")
        raise FileNotFoundError(error_msg)

    try:
        # Cargar Whisper
        print("üîÑ Cargando procesador de 'openai/whisper-small'...")
        whisper_processor = WhisperProcessor.from_pretrained("openai/whisper-small")
        print("‚úÖ Procesador 'small' cargado.")

        print("üîÑ Cargando arquitectura de 'openai/whisper-small'...")
        whisper_model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-small")
        print("‚úÖ Arquitectura 'small' cargada.")

        print(f"üîÑ Cargando pesos personalizados desde: {WHISPER_MODEL_PATH}")
        state_dict = load_file(WHISPER_MODEL_PATH, device="cpu")
        whisper_model.load_state_dict(state_dict, strict=False)
        
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        whisper_model.to(device)
        whisper_model.eval()
        print(f"‚úÖ Modelo Whisper listo en dispositivo '{device}'")
        print("--- ‚ú® Carga del modelo Whisper finalizada ---")

    except Exception as e:
        whisper_processor = None
        whisper_model = None
        print(f"‚ùå ERROR durante la carga de Whisper: {e}")
        raise e

def load_clinical_model():
    """Carga el modelo cl√≠nico BERT para diagn√≥stico."""
    global clinical_tokenizer, clinical_model
    if clinical_tokenizer is not None and clinical_model is not None:
        return

    print("--- üöÄ Iniciando carga del modelo cl√≠nico BERT ---")
    
    if not os.path.exists(CLINICAL_MODEL_PATH):
        error_msg = f"ERROR CR√çTICO: No se encontr√≥ el modelo cl√≠nico en {CLINICAL_MODEL_PATH}"
        print(f"‚ùå {error_msg}")
        raise FileNotFoundError(error_msg)

    try:
        # Cargar tokenizer y modelo base
        print("üîÑ Cargando tokenizer cl√≠nico...")
        clinical_tokenizer = AutoTokenizer.from_pretrained("emilyalsentzer/Bio_ClinicalBERT")
        
        print("üîÑ Cargando arquitectura del modelo...")
        clinical_model = AutoModelForSequenceClassification.from_pretrained(
            "emilyalsentzer/Bio_ClinicalBERT",
            num_labels=5  # Ajustar seg√∫n tu modelo
        )
        
        # Cargar pesos personalizados
        print(f"üîÑ Cargando pesos personalizados desde: {CLINICAL_MODEL_PATH}")
        # SOLUCI√ìN: A√±adir weights_only=True para seguridad en PyTorch >= 2.1
        state_dict = torch.load(CLINICAL_MODEL_PATH, map_location=torch.device('cpu'), weights_only=True)
        clinical_model.load_state_dict(state_dict)
        
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        clinical_model.to(device)
        clinical_model.eval()
        print(f"‚úÖ Modelo cl√≠nico listo en dispositivo '{device}'")
        print("--- ‚ú® Carga del modelo cl√≠nico finalizada ---")

    except Exception as e:
        clinical_tokenizer = None
        clinical_model = None
        print(f"‚ùå ERROR durante la carga del modelo cl√≠nico: {e}")
        raise e

def validate_wav_file(file_path):
    """Valida y verifica un archivo WAV."""
    try:
        with wave.open(file_path, 'rb') as wav_file:
            # Verificar par√°metros b√°sicos
            frames = wav_file.getnframes()
            sample_width = wav_file.getsampwidth()
            framerate = wav_file.getframerate()
            channels = wav_file.getnchannels()
            
            print(f"üìä WAV Info - Frames: {frames}, Sample Width: {sample_width}, Rate: {framerate}, Channels: {channels}")
            
            if frames == 0:
                print("‚ùå Archivo WAV vac√≠o")
                return False
                
            return True
    except Exception as e:
        print(f"‚ùå Error validando WAV: {e}")
        return False

def convert_to_standard_wav(input_path, output_path):
    """Convierte cualquier archivo de audio a WAV est√°ndar."""
    try:
        print(f"üîÑ Convirtiendo a WAV est√°ndar: {input_path}")
        
        # Intentar diferentes m√©todos de carga con pydub
        audio_segment = None
        methods = [
            lambda: AudioSegment.from_wav(input_path),
            lambda: AudioSegment.from_file(input_path, format="wav"),
            lambda: AudioSegment.from_file(input_path),
        ]
        
        for i, method in enumerate(methods, 1):
            try:
                print(f"üîÑ Intento {i} de carga...")
                audio_segment = method()
                break
            except Exception as e:
                print(f"‚ùå M√©todo {i} fall√≥: {e}")
                continue
        
        if audio_segment is None:
            print("‚ùå No se pudo cargar el archivo con pydub")
            return False
        
        # Normalizar formato
        audio_segment = audio_segment.set_frame_rate(16000)
        audio_segment = audio_segment.set_channels(1)
        audio_segment = audio_segment.set_sample_width(2)  # 16-bit
        
        # Exportar
        audio_segment.export(output_path, format="wav")
        print(f"‚úÖ Archivo convertido exitosamente a: {output_path}")
        return True
        
    except Exception as e:
        print(f"‚ùå Error en conversi√≥n: {e}")
        return False

def read_audio_raw(file_path):
    """Lee un archivo de audio interpret√°ndolo como datos raw."""
    try:
        print("üîÑ Intentando lectura raw del archivo...")
        
        with open(file_path, 'rb') as f:
            # Saltar header WAV t√≠pico (44 bytes)
            f.seek(44)
            raw_data = f.read()
        
        if len(raw_data) == 0:
            print("‚ùå No hay datos despu√©s del header")
            return None, None
        
        # Interpretar como 16-bit PCM
        if len(raw_data) % 2 != 0:
            raw_data = raw_data[:-1]  # Quitar byte extra si existe
        
        # Convertir bytes a array numpy
        audio_array = np.frombuffer(raw_data, dtype=np.int16)
        
        # Normalizar a float32 entre -1 y 1
        audio_array = audio_array.astype(np.float32) / 32768.0
        
        print(f"‚úÖ Lectura raw exitosa - Samples: {len(audio_array)}")
        return audio_array, 16000
        
    except Exception as e:
        print(f"‚ùå Error en lectura raw: {e}")
        return None, None

def procesar_audio_con_whisper(audio_path, language="es"):
    """Transcribe un archivo de audio usando Whisper con m√∫ltiples fallbacks mejorados."""
    try:
        print(f"üîç Verificando archivo de audio: {audio_path}")
        
        if not os.path.exists(audio_path) or os.path.getsize(audio_path) < 100:
            print(f"‚ùå Archivo de audio no encontrado o inv√°lido: {audio_path}")
            return None
        
        print(f"üìè Tama√±o del archivo: {os.path.getsize(audio_path)} bytes")
        
        audio_array, sample_rate = None, 16000
        
        # --- L√ìGICA DE CARGA DE AUDIO RESTAURADA ---
        # M√©todo 1: Validar WAV y cargar con soundfile
        if audio_path.lower().endswith('.wav'):
            if validate_wav_file(audio_path):
                try:
                    print("üîÑ M√©todo 1: Cargando WAV validado con soundfile...")
                    audio_array, sample_rate = sf.read(audio_path)
                    if audio_array.ndim > 1:
                        audio_array = audio_array.mean(axis=1)
                    print("‚úÖ Cargado con soundfile")
                except Exception as e:
                    print(f"‚ùå Fallo soundfile con WAV validado: {e}")
        
        # M√©todo 2: Intentar con pydub directamente (simplificado)
        if audio_array is None:
            try:
                print("üîÑ M√©todo 2: Cargando con pydub...")
                seg = AudioSegment.from_file(audio_path).set_channels(1).set_frame_rate(16000)
                samples = np.array(seg.get_array_of_samples()).astype(np.float32) / 32768.0
                if samples.size > 0:
                    audio_array = samples
                    sample_rate = 16000
                    print("‚úÖ Cargado con pydub")
            except Exception as e:
                print(f"‚ùå Fallo pydub: {e}")
        
        # M√©todo 3: Conversi√≥n a WAV est√°ndar
        if audio_array is None:
            try:
                print("üîÑ M√©todo 3: Convirtiendo a WAV est√°ndar...")
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                    temp_path = temp_file.name
                if convert_to_standard_wav(audio_path, temp_path):
                    audio_array, sample_rate = sf.read(temp_path)
                    if audio_array.ndim > 1:
                        audio_array = audio_array.mean(axis=1)
                    os.unlink(temp_path)
                    print("‚úÖ Cargado despu√©s de conversi√≥n est√°ndar")
            except Exception as e:
                print(f"‚ùå Fallo conversi√≥n est√°ndar: {e}")
                if 'temp_path' in locals() and os.path.exists(temp_path):
                    os.unlink(temp_path)
        
        # M√©todo 4: Lectura raw de datos (el que te funcionaba)
        if audio_array is None:
            audio_array, sample_rate = read_audio_raw(audio_path)
        
        # M√©todo 5: Librosa como √∫ltimo recurso
        if audio_array is None:
            try:
                print("üîÑ M√©todo 5: Librosa como √∫ltimo recurso...")
                audio_array, sample_rate = librosa.load(audio_path, sr=16000, mono=True)
                print("‚úÖ Cargado con librosa")
            except Exception as e:
                print(f"‚ùå Fallo librosa: {e}")
        # --- FIN DE LA L√ìGICA DE CARGA ---

        if audio_array is None or len(audio_array) == 0:
            print("‚ùå No se pudo cargar el archivo de audio con ning√∫n m√©todo")
            return None
        
        # Verificar y limpiar el audio
        if np.any(np.isnan(audio_array)) or np.any(np.isinf(audio_array)):
            print("‚ö†Ô∏è Limpiando valores inv√°lidos en el audio...")
            audio_array = np.nan_to_num(audio_array)
        
        max_val = np.max(np.abs(audio_array))
        if max_val > 1.0:
            audio_array = audio_array / max_val
        elif max_val == 0.0:
            print("‚ùå El audio no contiene se√±al (silencio completo)")
            return "El audio parece estar en silencio."
        
        duration = len(audio_array) / sample_rate
        print(f"‚úÖ Audio procesado exitosamente (duraci√≥n: {duration:.2f}s)")
        if duration < 0.1:
            print("‚ùå El audio es demasiado corto para procesar")
            return "El audio es demasiado corto."
        
        # Procesar con Whisper
        print("üîÑ Procesando con Whisper...")
        input_features = whisper_processor(
            audio_array, 
            sampling_rate=sample_rate, 
            return_tensors="pt"
        ).input_features.to(whisper_model.device)

        # SOLUCI√ìN: Forzar el idioma para evitar transcripciones incorrectas
        print(f"üó£Ô∏è Forzando idioma de transcripci√≥n a: '{language}'")
        forced_decoder_ids = whisper_processor.get_decoder_prompt_ids(language=language, task="transcribe")

        with torch.no_grad():
            print("üîÑ Generando transcripci√≥n...")
            predicted_ids = whisper_model.generate(
                input_features, 
                forced_decoder_ids=forced_decoder_ids, # <-- CAMBIO CLAVE
                max_length=448
            )
            transcripcion = whisper_processor.batch_decode(
                predicted_ids, 
                skip_special_tokens=True
            )[0]
        
        transcripcion_limpia = transcripcion.strip()
        print(f"‚úÖ Transcripci√≥n generada: '{transcripcion_limpia[:100]}...'")
        
        if not transcripcion_limpia:
            print("‚ö†Ô∏è Transcripci√≥n vac√≠a o inv√°lida")
            return "No se pudo generar transcripci√≥n del audio."
        
        return transcripcion_limpia

    except Exception as e:
        print(f"‚ùå Error cr√≠tico al transcribir el audio: {e}")
        print(f"üìã Traceback completo: {traceback.format_exc()}")
        return None

def generar_diagnostico_clinico(sintomas, historial):
    """Genera un diagn√≥stico basado en s√≠ntomas e historial m√©dico."""
    try:
        load_clinical_model()
        
        if not sintomas or not sintomas.strip():
            sintomas = "S√≠ntomas no especificados"
        if not historial or not historial.strip():
            historial = "Historial m√©dico no disponible"
        
        input_text = f"{sintomas.strip()} [SEP] {historial.strip()}"
        
        print(f"üîÑ Tokenizando texto para diagn√≥stico cl√≠nico: '{input_text[:100]}...'")
        inputs = clinical_tokenizer(
            input_text,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=512
        ).to(clinical_model.device)
        
        print("üîÑ Generando diagn√≥stico...")
        with torch.no_grad():
            outputs = clinical_model(**inputs)
            logits = outputs.logits
            probabilities = torch.softmax(logits, dim=1)
            confidence, predicted_class = torch.max(probabilities, dim=1)
            predicted_class = predicted_class.item()
            confidence = confidence.item()
        
        diagnosticos = {
            0: "Common cold", 1: "Pneumonia", 2: "Bronchitis",
            3: "Asthma exacerbation", 4: "Chronic obstructive pulmonary disease (COPD)"
        }
        diagnostico_en = diagnosticos.get(predicted_class, "Unknown condition")
        print(f"‚úÖ Diagn√≥stico generado: {diagnostico_en} (confianza: {confidence:.2f})")
        
        traducciones = {
            "Common cold": "Resfriado com√∫n", "Pneumonia": "Neumon√≠a",
            "Bronchitis": "Bronquitis", "Asthma exacerbation": "Exacerbaci√≥n de asma",
            "Chronic obstructive pulmonary disease (COPD)": "Enfermedad pulmonar obstructiva cr√≥nica (EPOC)",
            "Unknown condition": "Condici√≥n desconocida"
        }
        diagnostico_es = traducciones.get(diagnostico_en, "Condici√≥n desconocida")
        
        if confidence < 0.5:
            diagnostico_es += f" (Confianza baja: {confidence:.1%})"
            diagnostico_en += f" (Low confidence: {confidence:.1%})"
        
        return diagnostico_en, diagnostico_es

    except Exception as e:
        print(f"‚ùå Error al generar diagn√≥stico: {e}")
        print(f"üìã Traceback: {traceback.format_exc()}")
        return "Error generating diagnosis", "Error generando diagn√≥stico"

def analizar_audio_view(request, audio_id):
    """Vista para mostrar la p√°gina de an√°lisis de un audio espec√≠fico."""
    try:
        audio = get_object_or_404(AudioMedico, id=audio_id)
        diagnostico = Diagnostico.objects.filter(audio=audio).first()
        context = {'audio': audio, 'diagnostico': diagnostico}
        return render(request, 'analizar_audio.html', context)
    except Exception as e:
        print(f"‚ùå Error en vista de an√°lisis: {e}")
        return render(request, 'error.html', {'error': 'No se pudo cargar el audio'})

@csrf_exempt
@require_http_methods(["POST"])
def procesar_audio_ajax_view(request):
    """Vista AJAX para procesar un audio y generar diagn√≥stico."""
    try:
        data = json.loads(request.body)
        audio_id = data.get('audio_id')
        language = data.get('language', 'es') # Permite seleccionar idioma desde el frontend, por defecto 'es'

        if not audio_id:
            return JsonResponse({'success': False, 'error': 'ID de audio no proporcionado'}, status=400)

        load_custom_whisper_model()
        audio = get_object_or_404(AudioMedico, id=audio_id)
        audio_path = audio.archivo_audio.path
        print(f"üé§ Procesando audio ID {audio_id} desde: {audio_path}")

        transcripcion = procesar_audio_con_whisper(audio_path, language=language)
        if transcripcion is None:
            return JsonResponse({'success': False, 'error': 'No se pudo transcribir el audio. Verifique el formato y calidad del archivo.'}, status=500)

        sintomas = transcripcion
        historial = "Historial no especificado"
        
        diagnostico_en, diagnostico_es = generar_diagnostico_clinico(sintomas, historial)
        
        return JsonResponse({
            'success': True,
            'transcripcion': transcripcion,
            'diagnostico_en': diagnostico_en,
            'diagnostico_es': diagnostico_es
        })

    except FileNotFoundError as e:
        error_msg = f"Error de configuraci√≥n: {str(e)}"
        print(f"‚ùå {error_msg}")
        return JsonResponse({'success': False, 'error': error_msg}, status=500)
    except Exception as e:
        error_msg = f"Error inesperado: {str(e)}"
        print(f"‚ùå {error_msg}")
        print(f"üìã Traceback: {traceback.format_exc()}")
        return JsonResponse({'success': False, 'error': error_msg}, status=500)

@csrf_exempt
@require_http_methods(["POST"])
def guardar_resultados_ajax_view(request):
    """Guarda la transcripci√≥n y diagn√≥stico en la base de datos."""
    try:
        data = json.loads(request.body)
        audio_id = data.get('audio_id')
        transcripcion = data.get('transcripcion')
        diagnostico_en = data.get('diagnostico_en')
        diagnostico_es = data.get('diagnostico_es')

        if not all([audio_id, transcripcion, diagnostico_en, diagnostico_es]):
            return JsonResponse({'success': False, 'error': 'Datos incompletos'}, status=400)

        audio = get_object_or_404(AudioMedico, id=audio_id)

        contenido_diagnostico = f"""TRANSCRIPCI√ìN:
{transcripcion}

DIAGN√ìSTICO:
‚Ä¢ Espa√±ol: {diagnostico_es}
‚Ä¢ English: {diagnostico_en}

FECHA DE PROCESAMIENTO: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"""

        diagnostico, created = Diagnostico.objects.update_or_create(
            audio=audio,
            defaults={
                'transcripcion': contenido_diagnostico,
                'estado': 'completado'
            }
        )
        
        action = "creado" if created else "actualizado"
        print(f"üíæ Diagn√≥stico para audio ID {audio_id} {action} correctamente.")

        return JsonResponse({
            'success': True, 
            'message': f'Diagn√≥stico {action} con √©xito.',
            'diagnostico_id': diagnostico.id
        })
        
    except Exception as e:
        error_msg = f"Error al guardar: {str(e)}"
        print(f"‚ùå {error_msg}")
        print(f"üìã Traceback: {traceback.format_exc()}")
        return JsonResponse({'success': False, 'error': error_msg}, status=500)
